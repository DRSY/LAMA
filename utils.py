'''
Author: roy
Date: 2020-10-30 22:18:56
LastEditTime: 2020-10-30 22:21:40
LastEditors: Please set LastEditors
Description: In User Settings Edit
FilePath: /LAMA/utils.py
'''
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune

device = torch.device("cuda:3")
print(device)

class FoobarPruning(prune.BasePruningMethod):
    """
    Customized Pruning Method
    """
    PRUNING_TYPE = 'unstructured'

    def __init__(self, pregenerated_mask) -> None:
        super().__init__()
        self.pre_generated_mask = pregenerated_mask

    def compute_mask(self, t, default_mask):
        """
        """
        mask = self.pre_generated_mask.clone()
        return mask


def Foobar_pruning(module, name):
    """
    util function for pruning parameters of given module.name using corresponding mask generated by relation-specific mask generator
    Parameters:
    module: subclass of nn.Module
    name: name of parameters to be pruned
    id: id for the parameters in the parameters_tobe_pruned list
    """
    sub_module = getattr(module, name)
    shape = sub_module.size()
    random_mask = torch.bernoulli(torch.empty(
        *shape).uniform_(0, 1)).float().to(device)
    FoobarPruning.apply(module, name, pregenerated_mask=random_mask)
    return module

def remove_prune_reparametrization(module, name):
    prune.remove(module, name)