'''
Author: roy
Date: 2020-10-30 22:18:56
LastEditTime: 2020-10-31 14:24:08
LastEditors: Please set LastEditors
Description: In User Settings Edit
FilePath: /LAMA/utils.py
'''
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
from torch.distributions import Bernoulli

device = torch.device("cuda:3")
print(device)

class FoobarPruning(prune.BasePruningMethod):
    """
    Customized Pruning Method
    """
    PRUNING_TYPE = 'unstructured'

    def __init__(self, pregenerated_mask) -> None:
        super().__init__()
        self.pre_generated_mask = pregenerated_mask

    def compute_mask(self, t, default_mask):
        """
        """
        mask = self.pre_generated_mask.clone()
        return mask


def Foobar_pruning(module, name):
    """
    util function for pruning parameters of given module.name using corresponding mask generated by relation-specific mask generator
    Parameters:
    module: subclass of nn.Module
    name: name of parameters to be pruned
    id: id for the parameters in the parameters_tobe_pruned list
    """
    sub_module = getattr(module, name)
    shape = sub_module.size()
    random_mask = torch.bernoulli(torch.empty(
        *shape).uniform_(0, 1)).float().to(device)
    FoobarPruning.apply(module, name, pregenerated_mask=random_mask)
    return module

def remove_prune_reparametrization(module, name):
    """
    make pruning permanent
    """
    prune.remove(module, name)


def bernoulli_hard_sampler(probs):
    """
    Hard sampler for bernoulli distribution
    """
    Bernoulli_Sampler = Bernoulli(probs=probs)
    sample = Bernoulli_Sampler.sample()
    log_probs_of_sample = Bernoulli_Sampler.log_prob(sample)
    return sample, log_probs_of_sample


def bernoulli_soft_sampler(logits, temperature: float = 0.1):
    """
    Soft sampler for bernoulli distribution
    """
    uniform_variables = torch.rand(*logits.size())
    assert uniform_variables.shape == logits.shape
    samples = torch.sigmoid((logits + torch.log(uniform_variables) - torch.log(1-uniform_variables)) / temperature)
    return samples

if __name__ == "__main__":
    model = nn.Sequential(nn.Linear(32,100), nn.ReLU(), nn.Linear(100, 200))
    model.train()
    inputs = torch.randn(16, 32)
    pruning_mask_logits = model(inputs)
    assert pruning_mask_logits.requires_grad == True
    pruning_mask_probs = torch.sigmoid(pruning_mask_logits)
    soft_samples = bernoulli_soft_sampler(pruning_mask_logits, temperature=0.1)
    hard_samples, log_probs = bernoulli_hard_sampler(pruning_mask_probs)
    print(soft_samples.shape)
    print(soft_samples)